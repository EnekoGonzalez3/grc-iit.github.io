---
title: FAQ
---

# FAQ

## Basics

### Can I login with a password?

No. we only allow login via ssh keys. Send your public ssh key to the Ares system admin

### Why can’t I login with correct credentials?

Ares uses fail2ban to block offensive hosts to secure the server. Any IP that fails to login 5 times in the last 50 days will be blocked from accessing Ares for 24h. If you are blocked, please contact the system admin to unblock yourself.

### How to solve “Too many authentication failures error”?

It might be caused by too many SSH keys on your machine. You can try to add "-o IdentitiesOnly=yes" to your SSH command or client.

### How to allocate nodes for my test?

Slurm is the workload and resource manager in Ares. You must have an active job on nodes to be able to access any nodes. Here are some example commands, please check the slurm cheat sheet for more details about slurm. Please notice that the nodes are identified by the hostnames for low-speed networks (e.g., ares-comp-01). Hostnames for high-speed networks are not used by SLURM.
Check node status : `sinfo`
Check node status with a better look : `smap`
Check job queue : `squeue`
Cancel allocated job : `scancel JOBID`
Allocate a job without opening a new shell (this is recommended since the job will not be revoked after accidentally exiting the allocated shell) : `salloc -N 1 --no-shell`
Allocate a job with 4 specific compute nodes : `salloc -N 4 -p compute --nodelist=ares-comp-[8-10,13] --no-shell`
Allocate a job with 16 tasks on 4 nodes (other jobs may be allocated on the same nodes) : `salloc -n 16 -N 4 --no-shell`
Current wall time limit of a job is 48h. By default, a job will be terminated 48h after it starts. If you need to extend your running job, please contact the System Admin

### Can I reserve the nodes for my tests for a longer time?

Yes. Please contact the system admin to request node reservation. Once your reservation is approved, you will receive an email with a reservation ID. Then you can add `--reservation=reservation_id` to your allocation command to use your reservation.

### Can I jump in front of the job queue?

We follow FCFS policy in the resource scheduling. Users cannot change the priority of their jobs and jump in front of the job queue. You can, however, contact the users whose jobs are in front of you to negotiate a way to prioritize your job. You may also negotiate with other users about how to time sharing the nodes instead of exclusive allocation. You can do it by contacting each user specifically. You can find the names and contacts of all the users here. If you have urgent jobs to run, please contact the admin at `grc<plus>aresadmin<at>iit<dot>edu`.

### What are the roles of different nodes (master, compute)?

Master node is used as the login node. It is also supposed to be used for edit, compile and GUI-related commands. Any heavy workload should not be run on the master node. Please use compute nodes instead.

### How to run my test?

You are free to submit your job using sbatch, mpirun/mpiexec command, or your own scripts in an interactive session. For example, you can submit an MPI job script using sbatch. You also can allocate nodes using salloc, SSH to them, and use them however you want. The global home directory is visible on all nodes. You can prepare your codes/scripts/configuration on the master node and run them on any allocated nodes.
If you are sensitive to NFS access interference from other users or you want to get the best data access performance, you can copy all your stuff to local directory (`/mnt/{nvme|ssd|hdd}/$USER`), and do everything locally. However, please make sure you clean them to free up space for other users after your test.

### What toolchains are available?

We use a basic Ubuntu 22.04 stack. We provide modules for the user to load and use. The user is also free to install toolchains using `spack`.

### How to run commands with root privilege permission?

No normal user can have root permission on the master node. You can suggest the system admin your list of commands that people with similar research topics as you may need to run as root. The system admin will consider adding them to the list.

### What to do if I find some packages are missing?

You can send email to the System Admin to request for new packages. The system admin will consider installing them. Please provide the package name.

### How to use node-local storage media?

Since Ares is heterogenous, different nodes have different node-local storage.
Ares has a global shared NFS across the whole cluster which is mounted at /home. A symbolic link to the global NFS is also created at /mnt/common.
Each compute node has one local NVMe SSD, one SATA SSD, and one SATA HDD. They are mounted at /mnt/nvme, /mnt/ssd and /mnt/hdd, respectively. Every user has local directories in `/mnt/nvme/$USER`, `/mnt/ssd/$USER`, and `/mnt/hdd/$USER` on each compute node.

### Is this cluster homogeneous?

No.
In compute rack, 8 nodes (ares-comp-[01-08]) have Samsung 960 Evo 250GB NVMe SSD. The other 24 compute nodes (ares-comp-[09-32]) have Toshiba OCZ RD400 256GB NVMe SSD. In addition, each compute node has one Seagate 1TB SATA model LM049-2GH172 HDD, and one Samsung 860 Evo 512GB SATA SSD.
Lastly, the network connections between each pair of nodes could be different. All nodes are equipped with one Mellanox 40Gbps adapter.

### How to switch between high-speed and low-speed networks?

As shown in figure, each compute node has one high-speed (40Gbps) Ethernet and one low-speed (1Gbps) Ethernet. You can add -iface enp47s0 to your mpiexec command to explicitly use high-speed network. You can also switch between two networks with different hostnames. A postfix -40g  is added to standard hostname to distinguish two networks. For example, you can access compute node 10 from high-speed and low-speed networks using ares-comp-10-40g and ares-comp-10, respectively.

### How is the inter-job/user interference?

By default, nodes are shared by all users. Nodes which you are assigned to could be allocated to other users as long as remaining resources (e.g., CPU, memory) match the job requirement. You can avoid it by adding `--exclusive` to your job allocation command. Please use this feature only when necessary.


## OrangeFS

### How can I mount OrangeFS on compute/storage nodes?

Make sure you have the necessary sudo permission. Load the `orangefs` module.
Provide the orangefs configuration file, the server, and client list file, and the mount location

```bash
ares-orangefs-deploy <conf file> <server list> <client list> <mount_loc>
```

Example server file

    ares-comp-01-40g
    ares-comp-23-40g

Example client file

    ares-comp-01-40g
    ares-comp-23-40g

### How can I clean OrangeFS deployment from previous users or myself?

Run

```bash
ares-orangefs-terminate <conf file> <server list> <client list> <mount_loc>
```

## Miscellaneous

### How can I get monitoring data?

# Report Issue

Please contact the system admin at `grc<plus>aresadmin<at>iit<dot>edu` if you find an issue when using this cluster.
